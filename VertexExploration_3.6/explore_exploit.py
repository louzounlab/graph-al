from scipy.spatial.distance import cdist
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn import svm
from collections import Counter
from datetime import datetime
import pyprind
import sys
import time


class DistanceCalculator:
    # def __init__(self, mx, typ="euclidean"):
    #     self._mx = mx
    #     self._type = typ

    def euclidean(self, mx1, mx2, typ="euclidean"):
        # Get euclidean distances as 2D array
        dists = cdist(mx1, mx2, typ)
        # return the most distant rows
        return np.unravel_index(dists.argmax(), (mx1.shape[0], mx2.shape[0]))

    # TODO:implement using one class svm- http://scikit-learn.org/stable/modules/generated/sklearn.svm.OneClassSVM.html
    def one_class_learning(self, x_train, x_test):
        model = svm.OneClassSVM()
        model.fit(x_train)
        pred = model.predict(x_test)
        indices = np.where(pred == -1)[0]
        if len(indices) >=1:
            random_idx = np.random.randint(0, len(indices))
            return indices[random_idx]
        else:
            return np.random.randint(0, len(x_test))


class Learning:
    def machine_learning(self, x_train, y_train, x_test, smallest_class, clf=None):
        if clf is None:
            clf = RandomForestClassifier(n_estimators=200, class_weight="balanced")
        clf.fit(np.asmatrix(x_train, dtype=np.float32), y_train)
        probs = clf.predict_proba(x_test)
        return probs.argmax(0)[smallest_class]

    # TODO: implementation using keras
    def deep_learning(self, x_train, y_train, x_test, smallest_class):
        # pass
        from keras import Sequential
        from keras.callbacks import EarlyStopping
        from keras.layers import Dense, Dropout
        from keras.regularizers import l1_l2
        early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=50, mode='min', verbose=1)
        self.classifier = Sequential()
        self.classifier.add(Dense(300, kernel_initializer="he_normal", activation="relu", input_dim=x_train.shape[1]))
        self.classifier.add(Dropout(0.5))
        self.classifier.add(Dense(100, kernel_initializer='he_normal', activation='relu', kernel_regularizer=l1_l2(0.5)))
        self.classifier.add(Dropout(0.5))
        self.classifier.add(Dense(20, kernel_initializer='he_normal', activation='relu', kernel_regularizer=l1_l2(0.5)))
        self.classifier.add(Dropout(0.5))
        self.classifier.add(Dense(1, kernel_initializer='uniform', activation="sigmoid", kernel_regularizer=l1_l2(0.1)))

        self.classifier.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
        self.classifier.fit(x_train, y_train, validation_split=0.1, callbacks=[early_stopping], epochs=10,
                            batch_size=520, verbose=0)
        probs = self.classifier.predict_proba(x_test)
        return probs.argmax()

class ExploreExploit:
    def __init__(self, tags_vect, features_mx, recall, eps):
        self._tags = tags_vect
        self._features_mx = features_mx
        self._smallest_class = Counter(tags_vect).most_common()[-1][0]
        self._n_black = Counter(tags_vect).most_common()[-1][1]
        self._stop_cond = np.round(recall * self._n_black)
        self._eps = eps
        self._time = 0
        self._num_black_found = 0
        self._num_nodes = len(tags_vect)

    def _init(self):
        # initialize the train objects with copies
        self.x_test = type(self._features_mx)(self._features_mx)
        self.y_test = list(self._tags)
        self.x_train = None
        self.y_train = None
        self.bar = pyprind.ProgBar(len(self._tags), stream=sys.stdout)
        # explore first using distance
        idx1, idx2 = DistanceCalculator().euclidean(self.x_test, self.x_test)
        self._reveal(idx1)
        self._reveal(idx2)

    def run(self, dist_calc_type):
        self._num_black_found = 0
        self._init()
        while self._num_black_found < self._stop_cond:
            rand = np.random.uniform(0, 1)
            if rand < self._eps or not len(Counter(self.y_train)) > 1:
                if dist_calc_type == "euclidean":
                    idx = DistanceCalculator().euclidean(self.x_test, self.x_train)[0]
                else:
                    idx = DistanceCalculator().one_class_learning(self.x_train, self.x_test)
            else:
                idx = Learning().machine_learning(self.x_train, self.y_train, self.x_test, self._smallest_class)
            self._reveal(idx)
        return self._time/self._num_nodes, self.y_train

    def _reveal(self, idx):
        self._time += 1
        self.bar.update()
        # if self._time % 100 == 0:
        #     print(str(self._time) + " nodes were explored, time:" + str(datetime.now().time()))
        if self.y_test[idx] == 1:
            self._num_black_found += 1
        if self.x_train is None:
            self.x_train = self.x_test[idx, :]
            self.y_train = []
        else:
            self.x_train = np.vstack([self.x_train, self.x_test[idx, :]])
        self.y_train.append(self.y_test.pop(idx))
        self.x_test = np.delete(self.x_test, idx, 0)
