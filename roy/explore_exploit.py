import os
import numpy as np
from collections import Counter
import pyprind
import sys
from sklearn.metrics import f1_score, roc_auc_score, accuracy_score
from random import shuffle
from scipy.stats import entropy
import torch
from sklearn.preprocessing import normalize
import math
import pandas as pd
from networkx.algorithms.shortest_paths import weighted
import networkx as nx


from graph_measures import feature_meta
from graph_measures.features_infra.feature_calculators import FeatureMeta
from graph_measures.features_infra.graph_features import GraphFeatures
from graph_measures.features_algorithms.vertices.page_rank import PageRankCalculator
from gcn.data__loader import GraphLoader
from gcn.train import build_model, ModelRunner, mean_results, last_layer_representation
from tools import DistanceCalculator, DeepLearning, machine_learning, xgb_learning, aggregate, GraphNeighbors, StandardML

# chose features for the model
CHOSEN_FEATURES = feature_meta.NODE_FEATURES
NEIGHBOR_FEATURES = feature_meta.NEIGHBOR_FEATURES


class ExploreExploit:
    def __init__(self, features_mx, tags_vect, label, recall):
        self._tags = tags_vect
        self._features_mx = features_mx
        classes_counter = Counter(tags_vect)
        self._smallest_class = classes_counter.most_common()[-1-label][0]
        # self._largest_class = classes_counter.most_common()[0][0]
        self._n_black = classes_counter.most_common()[-1-label][1]
        self._n_classes = len(classes_counter)
        self._tags1 = [1 if y == self._smallest_class else 0 for y in self._tags]
        self._stop_cond = np.round(recall * self._n_black)
        self._recall = recall
        self._time = 0
        self._num_black_found = 0
        self._num_nodes = len(tags_vect)
        print("there are " + str(self._n_black) + " nodes to find, which are "
              + str(self._n_black/self._num_nodes*100) + "% of the whole data")

    def _init(self):
        self._time = 0
        self._num_black_found = 0
        self._bar = pyprind.ProgBar(len(self._tags), stream=sys.stdout)
        # initialize the train objects with copies
        self.x_test = type(self._features_mx)(self._features_mx)
        self.y_test = list(self._tags1)
        self.x_train = None
        self.y_train = None
        # explore first using distance
        idx1, idx2 = DistanceCalculator.euclidean(self.x_test, self.x_test)
        self._reveal(idx2)
        self._reveal(idx1)

    def run_recall(self, dist_calc_type, learn_type="ML", batch_size=10, eps=0):
        self._init()

        time_per_recall = {round(x, 2): 0 for x in np.arange(0, self._recall + 0.01, 0.05)}
        i = 1

        if learn_type == "DL":
            net = DeepLearning(self.x_train.shape[1])

        while self._num_black_found < self._stop_cond:
            rand = np.random.uniform(0, 1)
            if rand < eps or len(Counter(self.y_train)) <= 1:
                if dist_calc_type == "euclidean":
                    idx = [DistanceCalculator.euclidean(self.x_test, self.x_train)[0]]
                else:
                    idx = [DistanceCalculator.one_class_learning(self.x_train, self.x_test)]
            else:
                if learn_type == "DL":
                    idx = net.learn(self.x_train, self.y_train, self.x_test, batch_size=min(batch_size,
                                                                                            self._num_black_found))
                else:
                    idx = machine_learning(self.x_train, self.y_train, self.x_test,
                                           batch_size=min(batch_size, self._num_black_found))
            for j in sorted(idx, reverse=True):
                self._reveal(j)
                if self._num_black_found == np.round(self._n_black * 0.05 * i):
                    time_per_recall[round(i * 0.05, 2)] = self._time / self._num_nodes
                    temp = self._num_black_found
                    i += 1
                    while np.round(self._n_black * 0.05 * i) == temp:
                        time_per_recall[round(i * 0.05, 2)] = self._time / self._num_nodes
                        i += 1
        print(" ")
        return time_per_recall, self.y_train

    def _reveal(self, idx):
        self._time += 1
        self._bar.update()
        # if self._time % 100 == 0:
        #     print(str(self._time) + " nodes were explored, time:" + str(datetime.now().time()))
        if self.y_test[idx] == 1:
            self._num_black_found += 1
        if self.x_train is None:
            self.x_train = self.x_test[idx, :]
            self.y_train = []
        else:
            self.x_train = np.vstack([self.x_train, self.x_test[idx, :]])
        self.y_train.append(self.y_test.pop(idx))
        self.x_test = np.delete(self.x_test, idx, 0)


class Learning:
    def __init__(self, features_mx, tags, data_name, labels=1, epsilons=[0.05]):
        self._mx = features_mx
        self._tags = tags
        self._name = data_name
        self._labels = range(labels)
        self._epsilons = epsilons
        self._results = {y: {} for y in self._labels}
        self.eps_to_steps = {i: {y: {} for y in self._epsilons} for i in self._labels}

    def run_eps_greedy(self, dist_calc_type="one_class", learn_type="ML", recall=0.7, epochs=5):
        # finds recall achieved per percent of revealed data
        print("finding recall using greedy epsilon algorithm")

        for label in self._labels:
            print(label, dist_calc_type, learn_type)
            exploration = ExploreExploit(self._mx, self._tags, label, recall)
            for eps in self._epsilons:
                mean_steps_per_recall = {round(x, 2): 0 for x in np.arange(0, recall + 0.01, 0.05)}
                # when updated - update also steps_per_recall at
                print("epsilon =", eps)
                time_tag_dict = {}
                for i in range(1, epochs + 1):
                    steps_per_recall, tags = exploration.run_recall(dist_calc_type, learn_type, batch_size=10, eps=eps)
                    mean_steps_per_recall = {k: mean_steps_per_recall[k] + steps_per_recall[k]
                                             for k in mean_steps_per_recall}
                    time_tag_dict[i] = tags
                time_tag_df = pd.DataFrame.from_dict(time_tag_dict, orient="index").transpose()
                time_tag_df.to_csv(str(label) + "_" + dist_calc_type + "_output.csv")

                mean_steps_per_recall = {k: mean_steps_per_recall[k] / epochs
                                         for k in mean_steps_per_recall}
                print("the mean num of steps using eps = " + str(eps) + " is: " + str(mean_steps_per_recall[recall]))
                self.eps_to_steps[label][eps] = mean_steps_per_recall[recall]
                self._results[label]["eps_greedy_"+str(eps)] = mean_steps_per_recall

    def run_eps_greedy_f1(self, learn_type="ML", budget=20, epochs=5):
        print("finding f1 using greedy epsilon algorithm")

        exploration = ExploreExploitF1(self._mx, self._tags, budget=budget)
        for eps in self._epsilons:
            print("epsilon =", eps)
            mean_macrof1 = 0
            mean_microf1 = 0
            for i in range(1, epochs + 1):
                macrof1, microf1 = exploration.run(eps=eps)
                mean_macrof1 += macrof1
                mean_microf1 += microf1
            mean_macrof1 /= epochs
            mean_microf1 /= epochs

            print("the mean macroF1 is: " + str(mean_macrof1) + "the mean microF1 is: " + str(mean_microf1))

    def run_stand_recall(self, dist_calc_type="one_class", learn_type="ML", recall=0.7, epochs=3):
        # finds recall achieved per percent of revealed data
        print("finding recall using standard ml")
        my_range = np.linspace(0, recall, 15)
        my_range = [round(i, 2) for i in my_range]
        certainties = 4
        for label in self._labels:
            learning = StandardML(self._mx, self._tags, label)
            print(label, dist_calc_type, learn_type)
            temp_rand_results = {x: 0 for x in my_range}
            for certainty in np.linspace(0.15, 0.5, certainties):     # when updated - update also Results[rand]
                temp_recall = []
                temp_steps = []
                # temp_stand_results = {x: [0, 0] for x in my_range}
                certainty = round(certainty, 2)
                for i in range(1, epochs + 1):
                    # Results[self._name][label]["standML" + str(certainty) + "_" + str(i)] = {}
                    for p in my_range:
                        stand_recall, stand_steps, rand_recall, rand_steps = learning.recall_per_data(p, certainty)
                        temp_rand_results[p] += rand_recall
                        temp_recall.append(stand_recall)
                        temp_steps.append(stand_steps)
                        # temp_stand_results[p][0] += stand_recall
                        # temp_stand_results[p][1] += stand_steps
                p = np.polyfit(temp_steps, temp_recall, 3)
                f = np.poly1d(p)

                self._results[label]["standML_"+str(certainty)] = {max(f(x), 0): x for x in my_range}
                self._results[label]["rand"] = {temp_rand_results[x]/(epochs*certainties): x
                                                for x in temp_rand_results}

    def run_standard_ml(self, epochs=3):
        sum_acc_rf = 0
        sum_acc_dl = 0
        sum_acc_xgb = 0
        for i in range(epochs):
            learning = StandardML(self._mx, self._tags)
            acc_xgb, acc_rf, acc_dl = learning.run_acc()    # (print_train=True)
            print("accuracy is:  XGB - " + str(acc_xgb) +
                  "   RF - " + str(acc_rf) + "   NN - " + str(acc_dl))
            sum_acc_rf += acc_rf
            sum_acc_dl += acc_dl
            sum_acc_xgb += acc_xgb
        mean_acc_rf = sum_acc_rf / epochs
        mean_acc_dl = sum_acc_dl / epochs
        mean_acc_xgb = sum_acc_xgb / epochs
        print("mean accuracy is: XGB - " + str(mean_acc_xgb) + "   RF - "
              + str(mean_acc_rf) + "   NN - " + str(mean_acc_dl))

        # def run_al(self, learn_type="ML"):
        #     dist_calc_type = "one_class"
        #     print("active using learning type: " + str(learn_type))
        #     for label in ['moreno']:
        #         for eps in [0.05]:
        #             mean_steps = 0
        #             print(label, dist_calc_type)
        #             time_tag_dict = {}
        #             for i in range(1, 11):
        #                 exploration = ExploreExploit(self._tags[label], self._features_mx, 0.7, eps)
        #                 tags, n1 = exploration.run_opposite_active(dist_calc_type, learn_type)
        #                 time_tag_dict[i] = tags
        #                 Results['Active'] += n1
        #             time_tag_df = pd.DataFrame.from_dict(time_tag_dict, orient="index").transpose()
        #             time_tag_df.to_csv(label + "_active_" + dist_calc_type + "_output.csv")
        #             Results['Active'] /= 10


class ExploreExploitF1:
    def __init__(self, features_mx, tags_vect, budget):
        self._tags = tags_vect
        self._features_mx = features_mx
        self._n_classes = len(Counter(tags_vect))
        self._stop_cond = budget * self._n_classes
        self._num_nodes = len(tags_vect)

    def _init(self, n_nodes=4):
        # initialize the train objects with copies
        self.x_data = type(self._features_mx)(self._features_mx)
        self.y_data = list(self._tags)

        self.y_pool = [1]
        while min(Counter(self.y_pool).values()) < 5:
            indices = list(range(self._num_nodes))
            split = min(1000, self._num_nodes // 2)
            test_idx = np.random.choice(indices, size=split, replace=False)
            pool_idx = list(set(indices) - set(test_idx))
            self.x_pool = np.vstack([self.x_data[i] for i in pool_idx])
            self.y_pool = [self.y_data[i] for i in pool_idx]
            self.x_test = np.vstack([self.x_data[i] for i in test_idx])
            self.y_test = [self.y_data[i] for i in test_idx]

        self.x_train = None
        self.y_train = []
        c = {x: 0 for x in self._tags}
        indices = list(range(len(self.x_pool)))
        shuffle(indices)
        idx = []
        i = 0
        while min(c.values()) < 4:
            if c[self.y_pool[indices[i]]] < 4:
                idx.append(indices[i])
                c[self.y_pool[indices[i]]] += 1
            i += 1

        idx.sort(reverse=True)
        for i in idx:
            self._reveal(i)

    def run(self, eps=0):
        self._init(n_nodes=4)

        while len(self.x_train) <= self._stop_cond:
            rand = np.random.uniform(0, 1)
            if rand < eps:
                idx = np.random.choice(range(len(self.x_pool)))
            else:
                # idx = machine_learning(self.x_train, self.y_train, self.x_pool, is_f1=True)
                idx = xgb_learning(self.x_train, self.y_train, self.x_pool, is_f1=True)
            self._reveal(idx)

        y_pred = xgb_learning(self.x_train, self.y_train, self.x_train, is_stand_ml=True)

        train_macrof1 = f1_score(self.y_train, y_pred, average='macro')
        train_microf1 = f1_score(self.y_train, y_pred, average='micro')

        y_pred = xgb_learning(self.x_train, self.y_train, self.x_test, is_stand_ml=True)

        macrof1 = f1_score(self.y_test, y_pred, average='macro')
        microf1 = f1_score(self.y_test, y_pred, average='micro')

        return macrof1, microf1

    def _reveal(self, idx):
        if self.x_train is None:
            self.x_train = self.x_pool[idx, :]
        else:
            self.x_train = np.vstack([self.x_train, self.x_pool[idx, :]])
        self.y_train.append(self.y_pool.pop(idx))
        self.x_pool = np.delete(self.x_pool, idx, 0)


class GraphExploreExploitF1:
    def __init__(self, graph_loader: GraphLoader, budget: int, test_size: int):
        self._gnx = graph_loader
        self._labels = self._gnx.labels
        self._n_classes = self._gnx.num_labels
        self._test_size = test_size
        self._num_nodes = len(self._gnx.nodes_order)
        # self._tags = tags_vect
        # self._features_mx = features_mx
        self._stop_cond = budget * self._n_classes

    def _init(self, n_nodes=4):
        # initialize the train objects with copies
        # self.x_data = type(self._features_mx)(self._features_mx)
        # self.y_data = list(self._tags)

        tags_count = {0: 0}
        while min(tags_count.values()) < n_nodes:
            split = min(0.5, self._test_size / self._num_nodes)
            self._gnx.split_test(split, build_features=False)
            tags_count = Counter(self._gnx.get_tag_i(i) for i in self._gnx.train_idx)

        # set train size to 0
        self._gnx.split_train(0.000000001, build_features=False)

        self.x_train = None
        self.y_train = []
        c = {x: 0 for x in self._labels.values()}
        indices = self._gnx.val_idx
        indices = indices[torch.randperm(len(indices))]
        i = 0
        while min(c.values()) < n_nodes:
            # node = nodes[i]
            tag = self._gnx.get_tag_i(indices[i])
            if c[tag] < n_nodes:
                self._gnx.idx_val_to_train(indices[i], build_features=False)
                c[tag] += 1
            i += 1
        self._gnx.build_features_matrix()

    def run(self, eps=0.05):
        self._init(n_nodes=4)

        while len(self._gnx.train_idx) < self._stop_cond:
            rand = np.random.uniform(0, 1)
            if rand < eps:
                idx = np.random.choice(range(len(self._gnx.val_idx)))
            else:
                # idx = machine_learning(self.x_train, self.y_train, self.x_pool, is_f1=True)
                x_train, y_train, x_pool, y_pool = self._gnx.get_train_val()
                idx = machine_learning(x_train, y_train, x_pool, is_f1=True)
            self._gnx.idx_val_to_train(self._gnx.val_idx[idx])

        x_train, y_train, x_val, y_val, x_test, y_test = self._gnx.get_train_val_test()

        # train scores:
        y_pred = machine_learning(x_train, y_train, x_train, is_stand_ml=True)

        train_macrof1 = f1_score(y_train, y_pred, average='macro')
        train_microf1 = f1_score(y_train, y_pred, average='micro')

        # # validation scores:
        # y_pred = machine_learning(x_train, y_train, x_val, is_stand_ml=True)
        #
        # train_macrof1 = f1_score(y_val, y_pred, average='macro')
        # train_microf1 = f1_score(y_val, y_pred, average='micro')

        # test scores:
        y_pred = machine_learning(x_train, y_train, x_test, is_stand_ml=True)

        macrof1 = f1_score(y_test, y_pred, average='macro')
        microf1 = f1_score(y_test, y_pred, average='micro')

        return macrof1, microf1


# available options
Available_options = {'entropy', 'region_entropy', 'representation_euclidean_dist', 'representation_one_class_dist',
                     'centrality', 'Chang', 'geo_dist', 'geo_in_dist', 'geo_out_dist', 'Roy'}


class GraphExploreExploit:

    def __init__(self, data_set, budget: int, opt='entropy'):

        self._model_runner = build_model(data_set)
        self._gl = self._model_runner.loader
        self._models = {}
        self._opt = opt
        self._labels = self._gl.labels.cpu().numpy()
        self._labels_list = self._gl.labels_list
        self._n_classes = self._gl.num_labels
        self._num_nodes = self._gl.data_size
        self._pool = np.array([])
        self._revealed = np.array([])
        self._num_revealed = 0
        if budget < 1:
            self._stop_cond = math.ceil(budget * self._num_nodes)
        else:
            self._stop_cond = budget
        print("budget is {0:.2f}% of the data".format(self._stop_cond/self._num_nodes*100))

    def _init(self, n_nodes=1):
        # set train size to 0
        self._gl.split_test(1, build_features=True)
        self._pool = self._gl.test_idx.cpu().numpy()
        self._revealed = np.array([])
        self._num_revealed = 0

        # evaluate the model without labeled nodes
        results = self._model_runner.test()

        # randomly chose n_nodes nodes from each label
        c = {x: 0 for x in self._labels_list}
        indices = self._gl.test_idx
        indices = indices[torch.randperm(len(indices))].cpu().numpy()
        i = 0
        while min(c.values()) < n_nodes:
            tag = self._gl.get_tag_i(indices[i])
            if c[tag] < n_nodes:
                self._gl.idx_test_to_train(indices[i], build_features=False)
                c[tag] += 1
            i += 1
        self._pool = self._gl.test_idx.cpu().numpy()
        self._revealed = self._gl.base_train_idx.cpu().numpy()
        self._gl.build_features_matrix()

        return results

    def _reveal(self, idx, build_features=True):
        # self._gl.split_train(1, build_features=False)
        for i in idx:
            # self._gl.idx_test_to_val(self._pool[i], build_features=False)
            self._gl.idx_test_to_train(self._pool[i], build_features=False)
            self._num_revealed += 1
        self._revealed = np.append(self._revealed, self._pool[list(idx)])
        self._pool = np.delete(self._pool, list(idx), 0)
        if build_features:
            self._gl.build_features_matrix()

    def _train_and_eval(self, epochs, iterations=1, clear_model=True, verbose=1):
        res = []
        for j in range(iterations):
            if clear_model:
                self._models.clear()
            self._models = self._model_runner.train(epochs, self._models, verbose=verbose, early_stopping=False)
            res.append(self._model_runner.test(self._models))
        mean_res = mean_results(res)

        return mean_res

    def _explore(self, batch_size):
        idx = np.random.choice(len(self._pool), batch_size, replace=False)

        # # try balancing classes
        # idx = set()
        # test_probs = self._model_runner.predict_proba(self._models).cpu().numpy()
        # classes_revealed = Counter(self._labels[self._revealed])
        # # for _ in range(batch_size):
        # while len(idx) < batch_size:
        #     desired_class = min(classes_revealed.items(), key=operator.itemgetter(1))[0]
        #     classes_revealed[desired_class] += 1
        #     class_most_likely = np.argmax(test_probs[:, desired_class])
        #     idx.add(class_most_likely)
        #     test_probs[class_most_likely] = np.zeros(self._n_classes)

        return idx

    def _representation_distance(self, features_matrix=None):
        rep = last_layer_representation(self._models)
        for key in rep.keys():
            rep_vectors = rep[key].cpu().detach().numpy()
        # rep_vectors = features_matrix
        pool_rep = rep_vectors[self._pool]
        train_rep = rep_vectors[self._gl.base_train_idx.cpu()]
        # x_train, y_train, x_test, y_test = self._gl.get_train_test()
        # pool_rep = x_test
        # train_rep = x_train
        if self._opt == 'representation_one_class_dist':
            outlier_score = DistanceCalculator.one_class_learning(train_rep, pool_rep, scores=True)
        else:
            outlier_score = DistanceCalculator.euclidean(pool_rep, train_rep, scores=True)

        return outlier_score

    def _region_entropies(self, neighbors_matrix):
        classes_probs = self._model_runner.predict_proba(self._models, test_only=False).cpu()
        region_entropies = []
        for node in self._pool:
            reg_matrix = neighbors_matrix[node]
            if reg_matrix.size == 0:
                region_entropies.append(0)
            else:
                reg_proba = np.vstack(classes_probs[reg_matrix[0, j]] for j in range(reg_matrix[0].size))
                region_entropies.append(entropy(np.mean(reg_proba, axis=0)))

            # index_map = {self._pool[i]: i for i in range(len(self._pool))}
            # # delete columns of known neighbors
            # reg_matrix = np.delete(reg_matrix, np.where(np.isin(reg_matrix[0], self._revealed))[1], 1)

            # reg_entropies = np.vstack(entropies[index_map[reg_matrix[0, j]]] for j in range(reg_matrix[0].size))
            # weights = np.vstack(weight[reg_matrix[1, j]] for j in range(reg_matrix[1].size))
            # region_entropies.append(np.average(reg_entropies, weights=weights))

        return region_entropies

    def _geodesic_distance(self, nodes_order, graph_dists, ancestors, descendants):
        dists = []
        nodes_revealed = nodes_order[self._revealed]
        for i in self._pool:
            node = nodes_order[i]
            dist = []
            if self._opt in {'geo_dist', 'geo_in_dist', 'Roy'}:
                anc = ancestors[i].intersection(nodes_revealed)
                dist.extend([graph_dists[x][node] for x in anc])
            if self._opt in {'geo_dist', 'geo_out_dist', 'Roy'}:
                des = descendants[i].intersection(nodes_revealed)
                dist.extend([graph_dists[node][x] for x in des])
            if dist:
                dists.append(min(dist))
            else:
                dists.append(9)
        dist_to_train = np.array(dists)

        return dist_to_train

    def _active_learning(self, eps=0.05, batch_size=1, epochs=200, out_prog=True, clear_model=False, out_interval=25):
        if self._opt not in Available_options:
            print("option {} is not supported".format(self._opt))
            return

        # initializing parameters for plots
        if out_prog:
            results = {0: self._init()}
            prog_intervals = out_interval
            prog_iter = 1
        else:
            self._init()
            results = {}

        # preliminary calculation for exploitation
        # calculate the neighborhood matrix
        if self._opt == 'region_entropy':
            graph = self._gl.get_graph()
            gn = GraphNeighbors(graph)
            neighbors_matrix = gn.neighbors(second_order=False, self_node=False)
            # average_degree = np.mean([x[1] for x in g.degree()])
            # weight = [average_degree ** (1-i) for i in range(3)]
        if self._opt in {'centrality', 'Chang', 'Roy'}:
            page_rank_feature = {"page_rank": FeatureMeta(PageRankCalculator, {"pr"})}
            page_rank_matrix = self._gl.get_features(page_rank_feature)
            norm_page_rank = normalize(page_rank_matrix, axis=0, norm='max').reshape(-1)
        # if self._opt in {'representation_euclidean_dist', 'representation_one_class_dist', 'chang'}:
        #     rep_features = CHOSEN_FEATURES
        #     features_matrix = self._gl.get_features(rep_features, print_time=True)
        #     # replace all nan values of attractor basin to 100
        #     features_matrix[np.isnan(features_matrix)] = 100
        if self._opt in {'geo_dist', 'geo_in_dist', 'geo_out_dist', 'Roy'}:
            graph = self._gl.get_graph()
            nodes_order = np.array(self._gl.nodes_order)
            graph_dists = dict(weighted.all_pairs_dijkstra_path_length(graph, self._num_nodes, weight='weight'))
            ancestors = [nx.ancestors(graph, node) for node in sorted(graph)]
            descendants = [nx.descendants(graph, node) for node in sorted(graph)]

        cur_interval = 1

        while self._num_revealed < self._stop_cond:
            # making output for plot
            if out_prog and self._num_revealed >= cur_interval/prog_intervals*self._stop_cond:
                res = self._train_and_eval(epochs, iterations=prog_iter, clear_model=clear_model)
                percent_revealed = round(self._num_revealed / self._num_nodes * 100, 2)
                results[percent_revealed] = res
                val = list(res.values())[0]
                self._model_runner.data_logger.info(' '.join([self._opt, str(eps)]), percent_revealed,
                                                    val["loss"], val["acc"], val["mic_f1"], val["mac_f1"])
                cur_interval = np.floor(self._num_revealed/self._stop_cond*prog_intervals) + 1
            else:
                self._train_and_eval(epochs, clear_model=clear_model, verbose=0)

            # eps greedy algorithm choosing nodes to reveal
            rand = np.random.uniform(0, 1)
            # Explore
            if rand < eps:
                idx = self._explore(batch_size=batch_size)
            # Exploit
            else:
                # evaluate the samples
                if self._opt in {'representation_euclidean_dist', 'representation_one_class_dist', 'Chang'}:
                    outlier_score = self._representation_distance()

                if self._opt in {'entropy', 'Chang'}:
                    test_probs = self._model_runner.predict_proba(self._models).cpu()
                    entropies = entropy(test_probs.t())

                if self._opt == 'region_entropy':
                    region_entropies = self._region_entropies(neighbors_matrix=neighbors_matrix)

                if self._opt in {'geo_dist', 'geo_in_dist', 'geo_out_dist', 'Roy'}:
                    dist_to_train = self._geodesic_distance(nodes_order, graph_dists, ancestors, descendants)

                # build scores vector according to the evaluation method
                if self._opt == 'entropy':
                    scores = entropies
                elif self._opt == 'region_entropy':
                    scores = region_entropies
                elif self._opt in {'representation_euclidean_dist', 'representation_one_class_dist'}:
                    scores = outlier_score
                elif self._opt in {'geo_dist', 'geo_in_dist', 'geo_out_dist'}:
                    scores = dist_to_train
                elif self._opt == 'centrality':
                    scores = np.asarray([page_rank_matrix[x] for x in self._pool]).reshape(-1)
                elif self._opt == 'Chang':
                    c3 = max(0.7 * (1 - self._num_revealed/self._stop_cond), 0)
                    c1 = c2 = (1 - c3) / 2

                    density = normalize(outlier_score.reshape(1, -1)).reshape(-1)
                    norm_entropy = normalize(entropies.reshape(1, -1)).reshape(-1)
                    centrality = np.asarray([norm_page_rank[x] for x in self._pool]).reshape(-1)

                    scores = c1 * norm_entropy + c2 * density + c3 * centrality
                elif self._opt == 'Roy':
                    c1 = 0.7
                    c2 = 0.3

                    g_dists = normalize(dist_to_train.reshape(1, -1), norm='max').reshape(-1)
                    centrality = np.vstack(norm_page_rank[x] for x in self._pool).reshape(-1)

                    scores = c1 * g_dists + c2 * centrality

                # choose the best nodes
                idx = np.argpartition(scores, -batch_size)[-batch_size:]
                # idx = np.argpartition(scores, batch_size)[:batch_size]

            self._reveal(idx)

        # evaluate the model
        results[round(self._num_revealed/self._num_nodes*100, 2)] = \
            self._train_and_eval(epochs, clear_model=clear_model)
        return results

    def run(self, iterations=1, eps=0.05, batch_size=1, epochs=200, clear_model=False, out_prog=False, out_interval=25,
            option=None):

        if option:
            self._opt = option

        res = [self._active_learning(eps, batch_size, epochs, out_prog, clear_model, out_interval)
               for _ in range(iterations)]
        aggregated = aggregate(res)
        result = {}
        for name, res in aggregated.items():
            result[name] = {}
            for train_s, vals in res.items():
                result[name][train_s] = {}
                val_list = sorted(vals.items(), key=lambda x: x[0], reverse=True)
                result[name][train_s] = {key: np.mean(val) for key, val in val_list}

        return result

